{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Жёлтое такси в Нью-Йорке](https://www.coursera.org/learn/data-analysis-project/supplement/NuH2K/zhioltoie-taksi-v-n-iu-iorkie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нью-Йоркская комиссия по такси и лимузинам (TLC) предоставляет подробные анонимизированные данные о поездках клиентов с 2009 года. Машины, выкрашенные жёлтым, имеют право брать пассажиров на улицах в любом из пяти боро города.\n",
    "\n",
    "Сырые данные о поездках в жёлтом такси можно найти на сайте TLC: www.nyc.gov/html/tlc/html/about/trip_record_data.shtml Эти данные разбиты на файлы по месяцам. В каждом из файлов содержится следующая информация о поездках:\n",
    "* VendorID провайдер данных (одна из двух категорий)\n",
    "* tpep_pickup_datetime - время начала поездки\n",
    "* tpep_dropoff_datetime - время окончания поездки\n",
    "* passenger_count - количество пассажиров\n",
    "* trip_distance - расстояние по счётчику\n",
    "* pickup_longitude &\tpickup_latitude - долгота и широта точки начала поездки\n",
    "* dropoff_longitude\t& dropoff_latitude - долгота и широта точки окончания поездки\n",
    "* RatecodeID - тип тарифа (одна из шести категорий)\n",
    "* store_and_fwd_flag\t- бинарный флаг, показывающий, были ли данные о поездке получены немедленно после её окончания, или какое-то время хранились в памяти автомобиля\n",
    "* payment_type - способ оплаты (одна из шести категорий)\n",
    "* fare_amount - стоимость поездки по счётчику\n",
    "* extra - доплата за поездки в пиковые часы и ночью\n",
    "* mta_tax - налог на счётчик\n",
    "* tip_amount - размер чаевых\n",
    "* tolls_amount - доплата за проезд по платным дорогам\n",
    "* improvement_surcharge\t- доплата за проезд, взимаемая с каждой поездки с января 2015\n",
    "* total_amount - общая стоимость поездки\n",
    "\n",
    "Подробнее: http://www.nyc.gov/html/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача проекта — научиться предсказывать количество поездок в ближайшие часы в каждом районе Нью-Йорка; для простоты мы определим прямоугольные районы. Для того, чтобы её решить, сырые данные необходимо агрегировать по часам и районам. Агрегированные данные будут представлять собой почасовые временные ряды с количествами поездок из каждого района.\n",
    "\n",
    "Задачу прогнозирования таких рядов можно решать с помощью авторегрессионных моделей, прогнозируя каждый ряд независимо. Ряды явно имеют сложную сезонность — суточную, недельную и годовую, поэтому для их моделирования понадобится использовать модель ARIMA с дополнительной регрессией на внешние признаки.\n",
    "\n",
    "Чтобы улучшить такую модель, можно попытаться учесть:\n",
    "\n",
    "* взаимосвязи между рядами\n",
    "* дополнительные параметры поездок, которые можно посчитать по исходным данным\n",
    "* внешние календарные и географические признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения проекта вы научитесь:\n",
    "\n",
    "* работать с геоданными\n",
    "* прогнозировать временные ряды сложной структуры\n",
    "* строить и настраивать регрессионные модели, делающие совместные предсказания для большого количества взаимосвязанных рядов\n",
    "\n",
    "Похожие задачи возникают на практике, если вам необходимо спрогнозировать продажи большого количества товаров в большом количестве магазинов, объём снятия денег в сети банкоматов, посещаемость разных страниц сайта и т.д.\n",
    "\n",
    "В ходе выполнения проекта у вас будет свобода выбора хода решения, используемых средств анализа, библиотек и моделей. Также обратите внимание, что для его успешного выполнения вам нужно будет скачать и обработать от 10 до 200 гигабайт сырых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Conda_3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import euclidean\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Агрегирование данных в ячейках отобранных на второй неделе за период с января по март 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_region = pd.read_csv('data/df_regions/week4_region.csv', index_col=[0])\n",
    "\n",
    "N_regions = df_region.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions = pd.read_csv('data/df_regions/regions.csv', sep=';', index_col=['region'])\n",
    "\n",
    "NY_longitude = (-74.25559, -73.70001)\n",
    "NY_latirude = (40.49612, 40.91553)\n",
    "\n",
    "bin_NY_longitude = list(set(df_regions.west.values))\n",
    "bin_NY_longitude.append(NY_longitude[1])\n",
    "bin_NY_longitude.sort()\n",
    "bin_NY_latirude = list(set(df_regions.south.values))\n",
    "bin_NY_latirude.append(NY_latirude[1])\n",
    "bin_NY_latirude.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_periods(date_list, region_n = N_regions):\n",
    "    '''Агрегирование и сохранение данных из определенного региона'''\n",
    "    for n in date_list:\n",
    "        clear_df(pd.read_csv('data/yellow_tripdata/yellow_tripdata_20' + n + '.csv'),\n",
    "                 region_n,\n",
    "                 int('20' + n[:2]),\n",
    "                 int(n[-2:])).to_csv('data/df_regions/week6_df_features_' + n + '.csv')\n",
    "\n",
    "def clear_df(df, region_n, year_start, month_start, year_end=None, month_end=None, region=df_regions.index):\n",
    "    '''Агрегирование данных из определенной зоны'''\n",
    "    df = df[(((df.pickup_longitude > NY_longitude[0]) & (df.pickup_longitude < NY_longitude[1]))\n",
    "                  & ((df.pickup_latitude > NY_latirude[0]) & (df.pickup_latitude < NY_latirude[1])))]\n",
    "    \n",
    "    df.loc[:, 'count'] = 1\n",
    "\n",
    "    \n",
    "    ret = stats.binned_statistic_2d(x=df.pickup_longitude.values,\n",
    "                                    y=df.pickup_latitude.values,\n",
    "                                    values=df.VendorID,\n",
    "                                    statistic='count',\n",
    "                                    bins=[bin_NY_longitude, bin_NY_latirude],\n",
    "                                    expand_binnumbers=True)\n",
    "    df['region'] = (ret[3][0] - 1) * 50 + ret[3][1]\n",
    "\n",
    "    df = df[df['region'].isin(region_n)]\n",
    "\n",
    "    df.loc[:, 'tpep_pickup_datetime'] = pd.to_datetime(df.loc[:,'tpep_pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df.loc[:, 'tpep_dropoff_datetime'] = pd.to_datetime(df.loc[:,'tpep_dropoff_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df.loc[:, 'tpep_pickup_datetime_h'] = pd.to_datetime(df.loc[:,'tpep_pickup_datetime'].apply(lambda x: str(x)[0:13] + \":00:00\"),\n",
    "                                                         format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    df = df[((df.tpep_dropoff_datetime - df.tpep_pickup_datetime) > timedelta(0))\n",
    "            & (df.passenger_count > 0)\n",
    "            & (df.trip_distance > 0)]\n",
    "\n",
    "    if year_end==None or month_end==None:\n",
    "        if month_start > 0 and month_start < 12:\n",
    "            period = pd.date_range(str(month_start) + '/1/' + str(year_start), str(month_start+1) + '/1/' + str(year_start), freq=\"1H\")[:-1]\n",
    "        elif month_start == 12:\n",
    "            period = pd.date_range(str(month_start) + '/1/' + str(year_start), str(1) + '/1/' + str(year_start+1), freq=\"1H\")[:-1]\n",
    "        else:\n",
    "            print('Не верный формат данных')\n",
    "    else:\n",
    "        period = pd.date_range(str(month_start) + '/1/' + str(year_start), str(month_end) + '/1/' + str(year_end), freq=\"1H\")[:-1]\n",
    "    \n",
    "    df['mean_trip_time'] = (df['tpep_dropoff_datetime']-df['tpep_pickup_datetime'])/timedelta(minutes=1)\n",
    "    \n",
    "    df = df.loc[:, ['region', 'tpep_pickup_datetime_h', 'passenger_count', 'mean_trip_time', 'trip_distance', 'total_amount']].groupby(['region','tpep_pickup_datetime_h']).mean()\n",
    "    df.reset_index(inplace=True)  \n",
    "    \n",
    "    df.index = df['tpep_pickup_datetime_h']\n",
    "    df.drop(columns=['tpep_pickup_datetime_h'])\n",
    "    df_gen = pd.DataFrame(index=period)\n",
    "    for region in np.unique(np.unique((df.region))):\n",
    "        df_parse = df.loc[:,['passenger_count', 'mean_trip_time', 'trip_distance', 'total_amount']][df.region == region]\n",
    "        for column in df_parse.columns:\n",
    "            df_gen[(str(region), str(column))] = df_parse[str(column)]\n",
    "    df_gen.columns = pd.MultiIndex.from_tuples(df_gen.columns, names=['region', 'features'])\n",
    "    df_gen.fillna(0)\n",
    "\n",
    "    return df_gen\n",
    "\n",
    "def merge_df(date_list):\n",
    "    '''Объединение агрегированных данных'''\n",
    "    df = pd.read_csv('data/df_regions/df_group_' + date_list[0] + '.csv', index_col=[0])\n",
    "    df.index = pd.to_datetime(df.index, format='%Y-%m-%d %H:%M:%S')\n",
    "    for n in date_list[1:]:\n",
    "        df_merge = pd.read_csv('data/df_regions/df_group_' + n + '.csv', index_col=[0])\n",
    "        df_merge.index = pd.to_datetime(df_merge.index, format='%Y-%m-%d %H:%M:%S')\n",
    "        df = pd.concat([df, df_merge])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Conda_3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 8min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Агрегирование и сохранение данных для выбранных регионов\n",
    "temp = gen_periods([\n",
    "#     '16-01','16-02', '16-03', '16-04', '16-05', '16-06'\n",
    "    '15-01','15-02','15-03','15-04','15-05','15-06','15-07','15-08','15-09','15-10','15-11','15-12'\n",
    "], region_n = N_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
