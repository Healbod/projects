В отчете по данному этапу вы должны ответить на следующие вопросы:

1. Какие признаки имеют пропуски среди своих значений? Что могут означать пропуски в этих признаках (ответьте на этот вопрос для двух любых признаков)?
В признаке first_blood_time отсутствуют 19553 знач.
В признаке first_blood_team отсутствуют 19553 знач.
В признаке first_blood_player1 отсутствуют 19553 знач.
В признаке first_blood_player2 отсутствуют 43987 знач.
	Причина: в признаках first_blood_time, first_blood_team, first_blood_player1, first_blood_player2 отсутствуют 19553 значения так как событие "первая кровь" не успело произойти за первые 5 минут. 

В признаке radiant_bottle_time отсутствуют 15691 знач.
В признаке dire_bottle_time отсутствуют 16143 знач.
	Причина: Команда radiant или dire не приобретали предмет "bottle" 

В признаке radiant_courier_time отсутствуют 692 знач.
В признаке dire_courier_time отсутствуют 676 знач.
	Причина: Команда radiant или dire не приобретали предмет "courier"

В признаке radiant_flying_courier_time отсутствуют 27479 знач.
В признаке dire_flying_courier_time отсутствуют 26098 знач.
	Причина: Команда radiant или dire не приобретали предмет "flying_courier"

В признаке dire_first_ward_time отсутствуют 1826 знач.
В признаке radiant_first_ward_time отсутствуют 1836 знач.
	Причина: Команда radiant или dire не приобретали предмет "наблюдателя"

2. Как называется столбец, содержащий целевую переменную?
	radiant_win

3. Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями? Инструкцию по измерению времени можно найти ниже по тексту. Какое качество при этом получилось? Напомним, что в данном задании мы используем метрику качества AUC-ROC.
Время кросс-валидации для 30 деревьев составляет 0:00:55.807580
при этом качество обучения получилось равны 0.689503

4. Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Что бы вы предложили делать, чтобы ускорить его обучение при увеличении количества деревьев?
	Немного есть, но качество увеличивается незначительно и при этом значительно увеличивается время обучения. С другой стороны возможно переобучение.
	Для ускорения обучения при увеличении кол-ва деревьев можно использовать для обучения не всю выборку, а случайное подмножество или уменьшить глубину деревьев в градиентном бустинге.


1. Какое качество получилось у логистической регрессии над всеми исходными признаками? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?
	Лучший параметр регуляризации C составляет 0.01
Время кросс-валидации логической регрессии составляет 0:02:30.157014
при это качество обучения получилось равны 0.716315
	Время обучения логистическая регрессия увеличелось на 73% по сравнению с временем обучения градиентного бустинга при этом качество изменилось незначительно.

2. Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем вы можете объяснить это изменение?
	Лучший параметр регуляризации без категориальных параметров C составляет 0.01
Время кросс-валидации логической регрессии без кат параметров составляет 0:01:27.159715
при это качество обучения получилось равны 0.716315
	Качество не изменилось, так как эти параметры особо не влияют на качество обучения.

3. Сколько различных идентификаторов героев существует в данной игре?
	Кол-во уникальных герое составляет 108 при этом максимальный ID = 112

4. Какое получилось качество при добавлении "мешка слов" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Лучший параметр регуляризации использую "мешок слов" C составляет 0.1
Время кросс-валидации логической регрессии использую "мешок слов" составляет 0:02:48.492847
при это качество обучения получилось равны 0.750733
Качество увеличилось, так как выбор определенных персонажей влияет на результат матча.

5. Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?
Максимальное значение на тестовой выборке получилось равным 0.9965, минимальное - 0.0083
